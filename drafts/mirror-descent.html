<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Optimizing with constraints: reparametrization and geometry.</title>
  <meta name="author" content="Vlad" />
  <base href="//vene.ro">
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/main.css" />
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/pygment.css" />
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/typogrify.css" />
  <link rel="shortcut icon" href="//vene.ro/favicon.ico" />
  <link href="//vene.ro/" type="application/atom+xml"
        rel="alternate" title="Vlad Niculae ALL Atom Feed" />
  <link href="//fonts.googleapis.com/css?family=PT+Mono|PT+Serif" rel="stylesheet"> 

  <!-- OpenGraph Info -->


  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
  integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
  crossorigin="anonymous"></script>
  <script>

 (function () {
'use strict';

var macros = {};

var katexMath = (function () {
    var maths = document.querySelectorAll('.arithmatex'),
        tex;

    for (var i = 0; i < maths.length; i++) {
      tex = maths[i].textContent || maths[i].innerText;
      if (tex.startsWith('\\(') && tex.endsWith('\\)')) {
        katex.render(tex.slice(2, -2), maths[i], {
            'macros': macros,
            'displayMode': false,
            'globalGroup': true});
      } else if (tex.startsWith('\\[') && tex.endsWith('\\]')) {
        katex.render(tex.slice(2, -2), maths[i], {
            'macros': macros,
            'displayMode': true,
            'globalGroup': true});
      }
    }
});

(function () {
  var onReady = function onReady(fn) {
    if (document.addEventListener) {
      document.addEventListener("DOMContentLoaded", fn);
    } else {
      document.attachEvent("onreadystatechange", function () {
        if (document.readyState === "interactive") {
          fn();
        }
      });
    }
  };

  onReady(function () {
    if (typeof katex !== "undefined") {
      katexMath();
    }
  });
})();

}());
  </script>

</head>

<body>
<div id="container">
<header>
  <nav class="navmenu" id="navmenu">
    <li id="homelink"><a href="/">Vlad Niculae</a>
    </li><li class="menu"><a href="//vene.ro/papers.html">Papers</a>
    </li><li class="menu"><a href="//vene.ro/blog/">Blog</a>
    </li><li class="menu"><a href="//vene.ro/teaching.html">Teaching</a>
   </li>
   </nav>
 </header>
 <div id="main">
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="//vene.ro/drafts/mirror-descent.html" rel="bookmark"
           title="Permalink to Optimizing with constraints: reparametrization and geometry.">Optimizing with constraints: <br>reparametrization and&nbsp;geometry.</a></h1>
<p class="subtitle"><time datetime="2020-08-01T00:00:00+02:00">Sat, 01 Aug 2020</time><label for="mirror-descent" class="margin-toggle"> ⊕</label><input type="checkbox" id="mirror-descent" class="margin-toggle" /><span class="marginnote">Category: <a href="//vene.ro/category/presentation.html">presentation</a><br />
</span></p>    </header>

    <div class="entry-content">
      <script src="https://unpkg.com/d3@3/d3.min.js"></script>

<style type="text/css">

#plotdiv {text-align: center;}

.rules line, .rules path {
  shape-rendering: crispEdges;
  stroke: #00000;
}

.series path {
  fill: none;
  stroke: #348;
}

.labels {
    font-family: sans-serif;
    font-size: .7em;
}

.thick {
  stroke-width: 4px;
}

.dashed {
    stroke-width: 1px;
}

.unconstr{ fill: gray };
.constr{ fill: black };
</style>

<div class="arithmatex">\[
\newcommand\pfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\DP[2]{\left\langle #1, #2 \right\rangle}
\]</div>
<p>When training machine learning models, and deep networks in particular,
we typically use gradient-based methods. But if we require the weights to
satisfy some constraints, things quickly get more&nbsp;complicated.</p>
<p>I&#8217;ve recently learned that a few ways for handling constraints are deeply connected.
In this post, we will explore these connections and demonstrate them in PyTorch on a friendly&nbsp;example. </p>
<h1 id="why-constraints-are-challenging">Why constraints are challenging<a class="headerlink" href="#why-constraints-are-challenging" title="Permanent link">&para;</a></h1>
<p>In machine learning, we fit models to data by minimizing an&nbsp;objective,</p>
<div class="arithmatex">\[\min_{x \in \mathcal{X}} f(x). \tag{OPT}\]</div>
<p>Here, <span class="arithmatex">\(x\)</span> denotes the parameters to be learned, for instance, the neural network weights.
They typically take values in <span class="arithmatex">\(\mathcal{X}=\reals\)</span>, and we train networks by
choosing an initial configuration <span class="arithmatex">\(x^{(0)}\)</span> and successively applying
updates of the&nbsp;form:</p>
<div class="arithmatex">\[
x^{(t+1)} \leftarrow x^{(t)} - \alpha^{(t)} g(x^{(t)}).
\]</div>
<p>If <span class="arithmatex">\(f\)</span> is convex and differentiable and <span class="arithmatex">\(g(x) = \nabla f(x)\)</span> is the gradient of <span class="arithmatex">\(f,\)</span> this is
the acclaimed <em>gradient descent</em> method. In deep learning, we typically get
stochastic, non-descent methods that nonetheless perform well and are efficient.
Here, we will focus on a &#8220;nice&#8221;, differentiable <span class="arithmatex">\(f\)</span>, and we will see that even
so, constraints quickly complicate&nbsp;things.</p>
<p>For modeling reasons, we might want to impose <strong>constraints</strong> on some of the weights
<span class="arithmatex">\(x\)</span>.  Perhaps one of the parameter corresponds to the variance of a
distribution, and thus it cannot be negative. Or perhaps a parameter denotes
some sort of &#8220;gate&#8221;, or mixture between two alternatives <span class="arithmatex">\(xa_1 + (1-x)a_2\)</span>. 
In this case, we would need to constrain <span class="arithmatex">\(x \in [0, 1]\)</span>. This is often called a
<em>box constraint</em> and it is one of the most friendly types of inequality
constraint we might deal&nbsp;with.</p>
<p>For one-dimensional convex problems, <em>i.e.,</em> <span class="arithmatex">\(\mathcal{X} = [a, b] \subset
\reals\)</span>, box constraints do not complicate the problem: we can solve the
unconstrained problem <span class="arithmatex">\(x_{\text{unc}}^* = \arg\min_{x\in\reals} f(x)\)</span>.  If the
answer satisfies the constraint, then it must be the solution of the constrained
problem as well. If not, the answer can be found by <em>clipping</em> to the&nbsp;interval:</p>
<div class="arithmatex">\[ x^\star = \operatorname{clip}_{[a,b]}(x_\text{unc}^\star)
\coloneqq \min(a, \max(b, x_\text{unc}^\star)).
\]</div>
<details class="note"><summary>Proof</summary><p>We add non-negative dual variables <span class="arithmatex">\(\mu_a\)</span> and <span class="arithmatex">\(\mu_b\)</span> to handle the inequality
constraints <span class="arithmatex">\(x \geq a\)</span> and <span class="arithmatex">\(x \leq b\)</span>, and write the&nbsp;lagrangian,</p>
<div class="arithmatex">\[\mathcal{L}(x) = f(x) + \mu_a (a-x) + \mu_b(x-b).\]</div>
<p>An optimal <span class="arithmatex">\(x^\star\)</span> must satisfiy the original constraints <span class="arithmatex">\((a \leq x^\star \leq b)\)</span>
and be a stationary point of the&nbsp;lagrangian:</p>
<div class="arithmatex">\[ 
D_x \mathcal{L}(x^\star) = 0 \iff f'(x^\star) = \mu_a - \mu_b.
\tag{F}
\]</div>
<p>The dual variables must be non-negative and satisfy
complementary&nbsp;slackness:</p>
<div class="arithmatex">\[
\mu_a (a - x^\star) = 0, \quad\text{and}\quad \mu_b (x^\star - b) = 0.
\]</div>
<p>Let <span class="arithmatex">\(x^\star_\text{unc}\)</span> be the solution of the unconstrained problem,
satisfying  <span class="arithmatex">\(f'(x^\star_\text{unc})=0\)</span>. If 
<span class="arithmatex">\(a \leq x^\star_\text{unc} \leq b\)</span>, then <span class="arithmatex">\(x^\star=x^\star_\text{unc}\)</span>, and
choosing <span class="arithmatex">\(\mu_a=\mu_b=0\)</span> satisfies all&nbsp;conditions.</p>
<p>Otherwise, <span class="arithmatex">\(x^\star_\text{unc}\)</span> is either too small or too large.
Assume <span class="arithmatex">\(x^\star_\text{unc} &gt; a\)</span> and take <span class="arithmatex">\(x^\star = a\)</span>. Then we have <span class="arithmatex">\(\mu_b=0\)</span>,
and from (F) we must have <span class="arithmatex">\(\mu_a = f'(a)\)</span>. Is this a valid value for the
dual variable? We must check that <span class="arithmatex">\(f'(a) \geq 0\)</span>. Convex <span class="arithmatex">\(f\)</span> satisfies
<span class="arithmatex">\( f(a) - f(x) \leq f'(a)(a-x) \)</span>
for any <span class="arithmatex">\(x\)</span>, including the minimizer <span class="arithmatex">\(x=x^\star_\text{unc}\)</span>.
By assumption, <span class="arithmatex">\(a-x^\star_\text{unc} &gt; 0\)</span>, so we may divide by it&nbsp;yielding</p>
<div class="arithmatex">\[ \mu_a = f'(a) \geq \frac{f(a)-f(x^\star_\text{unc})}{a-x^\star_\text{unc}} \geq 0. \]</div>
<p>The case <span class="arithmatex">\( x^\star_\text{unc} &gt; b \)</span> follows&nbsp;similarly.</p>
</details>
<p>The following animation might convince you that this is&nbsp;true:</p>
<p><div id="plotdiv">
  <svg id="onedimplot" preserveAspectRatio="xMinYMin meet" viewBox="0 0 550 150"></svg> <br />
    <input type="range" min="-1" max="2" step=".001" oninput="plot(this.value)" onchange="plot(this.value)">
  </div></p>
<script>
var w = 500;
var h = 100;

var x = d3.scale.linear().domain([-2, 3]).range([0, w]);
var xint = d3.scale.linear().domain([0, 1]);
var y = d3.scale.linear().domain([ 0, 1]).range([h, 0]);

//  var svg = d3.select("body").append("svg")
//  .attr("width", w + 50)
//  .attr("height", h + 50);
var svg = d3.select("#onedimplot");
    var vis = svg.append("svg:g").attr("transform", "translate(25,25)")
    make_rules();

    plot(0.5);


    function plot(x0) {
        var quadratic = make_quadratic(x0);
        chart_line(quadratic, x0);
    }

    function make_quadratic(x0) {
            return (function(t) {
                    return 0.5 * (t - x0) * (t - x0) + 0.2;
            });
    }

function chart_line(func, x0) {
            vis.selectAll('.dots').remove();
            vis.selectAll('.series').remove();
    var g = vis.append("svg:g").classed("series", true)

    g.append("svg:path")
        .classed("dashed", true)
        .attr("d", function(d) { return d3.svg.line()(
          x.ticks(100).map(function(t) {
            return [ x(t), y(func(t)) ]
          })
         )})

    g.append("svg:path")
        .classed("thick", true)
        .attr("d", function(d) { return d3.svg.line()(
          xint.ticks(100).map(function(t) {
            return [ x(t), y(func(t)) ]
          })
                    )})


            vis.append('circle')
                .classed("dots", true)
                .classed("unconstr", true)
                .attr("r", 5)
                .attr("cx", function(d) { return x(x0); })
                .attr("cy", function(d) { return y(func(x0)); })

          var xstar = Math.min(Math.max(x0, 0), 1);

            vis.append('circle')
                .classed("dots", true)
                .classed("constr", true)
                .attr("r", 5)
                .attr("cx", function(d) { return x(xstar); })
                .attr("cy", function(d) { return y(func(xstar)); })
}

function make_rules() {
    var rules = vis.append("svg:g").classed("rules", true)

    function make_x_axis() {
        return d3.svg.axis()
                .scale(x)
                .orient("bottom")
                .ticks(10)
    }


    rules.append("svg:g").classed("grid x_grid", true)
            .attr("transform", "translate(0,"+h+")")
            .call(make_x_axis()
                .tickSize(0,0,0)
                .tickFormat("")
            )

    rules.append("svg:g").classed("labels x_labels", true)
            .attr("transform", "translate(0,"+h+")")
            .call(make_x_axis()
                .tickSize(1)
            )
}
</script>

<p>However, in dimension two or more, clipping no longer works, because of
interactions between the variables. We demonstate this on a quadratic problem
which will become the main focus of the rest of this&nbsp;post,</p>
<div class="arithmatex">\[ \min_{x \in \mathcal{X}} 
f(x) \coloneqq \frac{1}{2}~(x - x_0)^\top Q (x - x_0).\tag{QP} \]</div>
<p>Let us visualize this problem for the specific case of
the unit square <span class="arithmatex">\(\mathcal{X} = [0,1] \times [0,1] \subset \reals^2\)</span>,
with <span class="arithmatex">\(x_0 = (1.5, .1)\)</span>, and 
<span class="arithmatex">\(Q = \left(\begin{smallmatrix}3 &amp; 2 \\\\ 2 &amp; 3 \end{smallmatrix}\right)\)</span>.
If not for the constraints, since <span class="arithmatex">\(Q\)</span> is positive definite, the minimum
would be <span class="arithmatex">\(x^\star_\text{unc} = x_0\)</span>.<label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle"/><span class="sidenote">Because <span class="arithmatex">\(f(x_0)=0,\)</span> and positive
definiteness guarantess <span class="arithmatex">\(f(x) &gt; 0\)</span> for any <span class="arithmatex">\(x \neq x_0\)</span>.</span>
But a contour plot shows that the constrained minimum <span class="arithmatex">\(x^\star\)</span> is not the same as the
result of clipping the unconstrained minimum to the&nbsp;box.</p>
<p><img alt="quadratic landscape" src="/images/mirror_quad_landscape.png"></img></p>
<p>This means that, in general, we cannot simply ignore the constraints and apply
them at the end, but we need to bake them into our optimization strategy.<label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle"/><span class="sidenote">
There is an important special case where (<span class="caps">QP</span>) can be solved exactly: the
case <span class="arithmatex">\(Q = I\)</span>. In this case, the problem becomes
<span class="arithmatex">\(\arg\min_{x \in \mathcal{X}} \| x - x_0 \|^2_2,\)</span>
which is known as the <em>euclidean projection</em> of <span class="arithmatex">\(x_0\)</span> onto <span class="arithmatex">\(\mathcal{X}\)</span>.
If <span class="arithmatex">\(\mathcal{X}\)</span> are box constraints, the projection decomposes into a series of
independent 1-d projections, which we&#8217;ve seen can be solved by&nbsp;clipping.</span></p>
<h2 id="ways-to-deal-with-constraints">Ways to deal with constraints.<a class="headerlink" href="#ways-to-deal-with-constraints" title="Permanent link">&para;</a></h2>
<p>When faced with a box-constrained optimization problem, these are the ideas that
most practitioners would turn to.<label for="sn-3" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-3" class="margin-toggle"/><span class="sidenote">This turns out to be a handy personality
quiz to see if somebody resonates more with neural networks or with convex&nbsp;optimization.</span></p>
<ol>
<li>
<p><em>Reparamtrization (<span class="caps">REP</span>).</em> Circumvent the constraints on <span class="arithmatex">\(x\)</span>, 
    by expressing the function in terms of unconstrained variables <span class="arithmatex">\(u\)</span>
    such that <span class="arithmatex">\(x_i = \sigma(u_i)\)</span>, where <span class="arithmatex">\(\sigma : \reals \to \mathcal{X}\)</span> is a
    &#8220;squishing&#8221; nonlinearity.
    We can then perform unconstrained minimiziation on <span class="arithmatex">\(f \circ \sigma\)</span>.
    For <span class="arithmatex">\(\mathcal{X}=[0,1]^d\)</span>, we may use the logistic
    function<label for="sn-4" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-4" class="margin-toggle"/><span class="sidenote">General intervals <span class="arithmatex">\([a,b]\)</span> are obtained by affinely
    transforming <span class="arithmatex">\([0,1]\)</span>.</span></p>
<div class="arithmatex">\[ \sigma(u) = \frac{1}{1 + \exp(-u)}.\]</div>
</li>
<li>
<p><em>Projected gradient (<span class="caps">PG</span>).</em> Perform unconstrained gradient updates, then
    project back onto the domain after each&nbsp;update:</p>
<div class="arithmatex">\[
\begin{aligned}
x^{(t+0.5)} &amp;\leftarrow x^{(t)} - \alpha^{(t)} g(x^{(t)}) \\
x^{(t+1)} &amp;\leftarrow \operatorname{Proj}_\mathcal{X}\big(x^{(t+0.5)}\big)
\\
\end{aligned}
\]</div>
</li>
</ol>
<p><span class="caps">REP</span> is convenient when working with neural network libraries like PyTorch,
because it can be implemented just by changing our model, without requiring
modifications to the optimization code. However, the resulting problem (after
reparametrization) is no longer convex in <span class="arithmatex">\(u\)</span>, even if the original problem was
convex in <span class="arithmatex">\(x\)</span>. <span class="caps">PG</span> directly solves the convex optimization problem (<span class="caps">QP</span>), but
the intermediate iterates <span class="arithmatex">\(x^{(t+0.5)}\)</span> can leave <span class="arithmatex">\(\mathcal{X}\)</span>,
leading to a possibly less stable or too aggressive&nbsp;trajectory.</p>
<p>In this post, we will explore the connection between the two by studying <em>mirror
descent</em> and its information-geometric interpretation as natural gradient
in a dual space. But first, let&#8217;s explore our two initial&nbsp;ideas.</p>
<h3 id="reparametrization">Reparametrization.<a class="headerlink" href="#reparametrization" title="Permanent link">&para;</a></h3>
<p>Instead of optimizing w.r.t. the constrained variables <span class="arithmatex">\(x\)</span>, we introduce an
underlying variable <span class="arithmatex">\(u\)</span>, such that <span class="arithmatex">\(x_i = \sigma(u_i)\)</span>.<label for="sn-5" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-5" class="margin-toggle"/><span class="sidenote">This seems to be the
more common method among neural network practitioners; one
place where it shows up often is <em>neural variational inference</em>, where we would
constrain the variance of a learned distribution using a <em>softplus</em>
function.</span>
In our case, we use a logistic sigmoid reparametrization to get the
unconstrained non-convex&nbsp;problem</p>
<div class="arithmatex">\[ \min_{u \in \reals^2} f(\sigma(u)), \]</div>
<p>where <span class="arithmatex">\(\sigma\)</span> is applied element-wise.  Let&#8217;s first implement our function
<span class="arithmatex">\(f(x) = \frac{1}{2} (x - x_0)^\top Q (x - x_0)\)</span>:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x_star</span>
    <span class="n">Qz</span> <span class="o">=</span> <span class="n">z</span> <span class="o">@</span> <span class="n">Q</span>
    <span class="k">return</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij,ij,i&quot;</span><span class="p">,</span> <span class="n">Qz</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
</code></pre></div>


<p>When reparametrizing, <span class="arithmatex">\(x\)</span> is no longer a learned parameter, but a function of
the learned parameter <span class="arithmatex">\(u\)</span>. The chain rule&nbsp;gives</p>
<!--%$$ D_u f(\sigma(u)) = {D_x}f(\sigma(u)) \cdot D_u\sigma(u),$$-->

<div class="arithmatex">\[ \pfrac{}{u} f(\sigma(u)) = \pfrac{f(x)}{x}\biggr\rvert_{x=\sigma(u)} \pfrac{\sigma(u)}{u} \]</div>
<!--
$$ \pfrac{}{u} f(\sigma(u)) = \pfrac{f(\sigma(u))}{x} \pfrac{\sigma(u)}{u} $$

$$ \nabla_{u} f(\sigma(u)) = \nabla_x f(\sigma(u))  \pfrac{\sigma(u)}{u} $$

$$ \nabla_{u} f(\sigma(u)) = \nabla_x f(\sigma(u))  J_\sigma(u) $$
-->

<p>but PyTorch autodiff does this automatically for us.
We may now write a minimalist gradient-based optimization&nbsp;loop:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">optim_reparam</span><span class="p">(</span><span class="n">u_init</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">u_init</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">u_</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="n">f</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">u_</span><span class="p">))</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># compute grad wrt u_</span>
        <span class="n">u</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span>  <span class="c1"># take gradient step</span>
    <span class="k">return</span> <span class="n">u</span>
</code></pre></div>


<p>With a very small learning rate, we get a glimpse into the dynamics of this
method. For comparison, we include the unconstrained&nbsp;trajectory.</p>
<p><img alt="quadratic landscape" src="/images/mirror_quad_lr0.010_reparam.png"></img></p>
<p>In practice, we would use a much larger learning rate to accelerate&nbsp;optimization:</p>
<p><img alt="quadratic landscape" src="/images/mirror_quad_lr0.200_reparam.png"></img></p>
<p>We can see that even with a large learning rate, the reparametrization method
takes much smaller steps, especially as it gets closer to the boundary of the
domain. At any point <span class="arithmatex">\(u\)</span>, recall the reparametrized&nbsp;gradient:</p>
<div class="arithmatex">\[ \pfrac{}{u} f(\sigma(u)) = \pfrac{f(x)}{x}\biggr\rvert_{x=\sigma(u)} \pfrac{\sigma(u)}{u}. \]</div>
<p>This is the unconstrained gradient at <span class="arithmatex">\(x=\sigma(u)\)</span>, rescaled by the Jacobian of <span class="arithmatex">\(\sigma\)</span>.
Since <span class="arithmatex">\(\sigma\)</span> acts elementwise, its Jacobian is a diagonal matrix, with
<span class="arithmatex">\(\pfrac{\sigma(u)_i}{u_i}  = \sigma(u_i)(1 - \sigma(u_i)) = x_i (1 - x_i).\)</span> We can thus see
that as <span class="arithmatex">\(x_i\)</span> approaches <span class="arithmatex">\(0\)</span> or <span class="arithmatex">\(1\)</span>, the reparametrization rescales the
gradient <strong>severely</strong>, bringing the effective step size toward 0. Remember, this
happens <em>automatically</em> via the chain rule! But, although slowly, and along a
slightly winding trajectory, our method finds the right&nbsp;answer.</p>
<h3 id="projected-gradient">Projected Gradient<a class="headerlink" href="#projected-gradient" title="Permanent link">&para;</a></h3>
<p>The projected gradient method is particularly well suited to handling &#8220;simple&#8221; constraints
like the box case, but, unlike reparametrization, requires a different kind of
expertise to get running in the case of complicated constraints.
<label for="sn-6" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-6" class="margin-toggle"/><span class="sidenote"><span class="caps">PG</span> is very popular in convex optimization, useful both for theory and for
practice. However, it does not seem to be so widely used in the pure neural
network world, perhaps mostly because it is not directly supported by the
built-in optimizers in major frameworks.</span>
For box constraints, the projection can be computed efficiently, since
<span class="arithmatex">\(\big[\!\operatorname{Proj}_{[0,1]^d}(x)\big]_i = \operatorname{clip}_{[0,1]}(x_i).\)</span>
The implementation&nbsp;follows:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">optim_pg</span><span class="p">(</span><span class="n">x_init</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_init</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">x_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="n">f</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># compute grad wrt x_</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span>  <span class="c1"># take gradient step</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># project</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div>


<p><img alt="quadratic landscape" src="/images/mirror_quad_lr0.010_pg.png"></img></p>
<p>It looks like the projected gradient method tends to follow the unconstrained
trajectory while sticking to the boundary of the domain. Of course, with larger
steps, the differences become more&nbsp;pronounced.</p>
<p><img alt="quadratic landscape" src="/images/mirror_quad_lr0.200_pg.png"></img></p>
<p>In this instance, <span class="caps">PG</span> is the clear winner: look how fast it makes progress. With
less well-behaved and non-convex functions this need not be the case. So we are
motivated to delve deeper and explore how <span class="caps">PG</span> and <span class="caps">REP</span> relate, despite seeming so&nbsp;different. </p>
<h2 id="generalizing-the-projected-gradient-method-with-divergences">Generalizing the projected gradient method with divergences<a class="headerlink" href="#generalizing-the-projected-gradient-method-with-divergences" title="Permanent link">&para;</a></h2>
<p>In the projected gradient method, we take unconstrained steps, which might take
us outside of <span class="arithmatex">\(\mathcal{X}\)</span>, and then move the solution back to <span class="arithmatex">\(\mathcal{X}\)</span> by&nbsp;projection:</p>
<div class="arithmatex">\[ x^{(t+1)} \leftarrow \operatorname{Proj}_\mathcal{X}\big(x^{(t+0.5)}\big). \]</div>
<p>Projection finds the point <span class="arithmatex">\(x \in \mathcal{X}\)</span> closest to <span class="arithmatex">\(x^{(t+0.5)}\)</span>,&nbsp;i.e.,</p>
<div class="arithmatex">\[ \operatorname{Proj}_\mathcal{X}\big(x^{(t+0.5)}\big) = \argmin_{x \in \mathcal{X}} \| x - x^{(t+0.5)} \|. \]</div>
<p>This update is motivated by a locally-linear&nbsp;approximation,</p>
<div class="arithmatex">\[ x^{(t+1)} \leftarrow \arg\min_{x \in \mathcal{X}}  \DP{\nabla f(x^{(t)})}{x} + \frac{1}{2\alpha_t}\|x - x^{(t)}\|^2. \tag{GD}
\]</div>
<details class="note"><summary>Explanation</summary><p>Why does this update make sense, and where does it come from? We are trying to
minimize a function <span class="arithmatex">\(f(x)\)</span>, but we don&#8217;t know what it looks like globally: we only
have access to its value <span class="arithmatex">\(f(x)\)</span> and its gradient <span class="arithmatex">\(\nabla f(x)\)</span> at points <span class="arithmatex">\(x\)</span>
that we may query one at a time. At any point <span class="arithmatex">\(x_0\)</span>,
the first-order Taylor expansion&nbsp;is:</p>
<div class="arithmatex">\[ f(x_0 + \delta) = f(x_0) + \DP{\nabla f(x_0)}{\delta} + o(\|\delta\|). \]</div>
<p>To get a linear approximation of <span class="arithmatex">\(f\)</span> we can plug in <span class="arithmatex">\(\delta = x - x_0\)</span>:</p>
<div class="arithmatex">\[ f(x) =  f(x_0) + \DP{\nabla f(x_0)}{x - x_0} + o(\|x - x_0\|). \]</div>
<p>So as long as <span class="arithmatex">\(x\)</span> is not too far from <span class="arithmatex">\(x_0\)</span>, we&nbsp;have </p>
<div class="arithmatex">\[f(x) \approx \tilde{f}_{x_0}(x) \coloneqq f(x_0) + \DP{\nabla f(x_0)}{x - x_0}.\]</div>
<p>This affine approximation is much easier to
minimize, but it is only accurate locally, therefore, we use it iteratively,
taking a small step, then updating the&nbsp;approximation:</p>
<div class="arithmatex">\[ 
x^{(t+1)} \leftarrow \arg\min_{x \in \mathcal{X}} \tilde f_{x^{(t)}}(x) + \frac{1}{2\alpha_t}\|x - x^{(t)}\|^2. 
\]</div>
<p>where the term on the right keeps us close to <span class="arithmatex">\(x^{(t)}\)</span> to ensure the
approximation is not too bad. Clearing up the constant terms from inside the
<span class="arithmatex">\(\arg\min\)</span> yields the desired&nbsp;expression.</p>
</details>
<p>If <span class="arithmatex">\(\mathcal{X}=\reals\)</span>, the problem (<span class="caps">GD</span>) can be solved by setting the gradient
to 0, which recovers the gradient descent update. Otherwise, we get exactly the
projected gradient&nbsp;update.</p>
<details class="note"><summary>Derivation</summary><div class="arithmatex">\[
\begin{aligned}
 &amp; \arg\min_{x \in \mathcal{X}} \DP{x}{\nabla f(x^{(t)})} + \frac{1}{2\alpha_t} \|x-x^{(t)}\|^2 \\
=&amp; \arg\min_{x \in \mathcal{X}} \DP{x}{\nabla f(x^{(t)})} + \frac{1}{2\alpha_t} \|x\|^2 - \frac{1}{\alpha_t} \DP{x}{x^{(t)}} \\
=&amp; \arg\min_{x \in \mathcal{X}} \alpha_t \DP{x}{\nabla f(x^{(t)})} + \frac{1}{2} \|x\|^2 - \DP{x}{x^{(t)}} \\
=&amp; \arg\min_{x \in \mathcal{X}} \DP{x}{\underbrace{\alpha_t \nabla f(x^{(t)}) - x^{(t)}}_{-x^{(t+0.5)}}} + \frac{1}{2} \|x\|^2 \\
=&amp; \arg\min_{x \in \mathcal{X}} \frac{1}{2} \| x - x^{(t+0.5)} \|^2 \textcolor{gray}{ - \frac{1}{2} \|x^{(t+0.5)}\|} \\
=&amp; \operatorname{Proj}_{\mathcal{X}} (x^{(t+0.5)}).
\end{aligned}
\]</div>
</details>
<p>The function <span class="arithmatex">\(D(x, y) = \| x - y \|^2 = \sum_i (x_i - y_i)^2\)</span> is the <em>squared Euclidean distance</em>.
Here, geometry starts to come into play!  Euclidean geometry is
convenient and comfortable for thinking about spaces like <span class="arithmatex">\(\reals^d,\)</span> but not
all quantities are well characterized by it. Our case of variables constrained
on <span class="arithmatex">\([0, 1]\)</span> provide a good example: the difference between .50 and .51 seems
like should not be the same as the difference between .98 and .99. A useful
generalization of distances is provided by the Bregman divergence<label for="sn-7" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-7" class="margin-toggle"/><span class="sidenote">Formally,
<span class="arithmatex">\(\psi\)</span> must be continuously differentiable and strictly&nbsp;convex.</span></p>
<div class="arithmatex">\[ D_\Psi(x, y) = \Psi(x) - \Psi(y) - \DP{\nabla \Psi(y)}{x - y}, \]</div>
<p>which induces the <strong>mirror descent</strong>&nbsp;algorithm,</p>
<div class="arithmatex">\[ x^{(t+1)} \leftarrow \arg\min_{x \in \mathcal{X}}  \DP{\nabla f(x^{(t)})}{x} + \frac{1}{\alpha_t}D_\psi(x, x^{(t)}). \tag{MD}
\]</div>
<p>which after derivation&nbsp;gives</p>
<div class="arithmatex">\[ x^{(t+1)} = \psi^{-1}(\psi(x^{(t)}) - \alpha_t \nabla f(x^{(t)})).
\]</div>
<p>where <span class="arithmatex">\(\psi(x) \coloneqq \nabla \Psi(x)\)</span>. Let&#8217;s make this more&nbsp;concrete.</p>
<p>Notice that <span class="arithmatex">\(D_{\| \cdot \|^2}\)</span> is the squared Euclidean distance, which we&#8217;ve
seen induces the projected gradient method, but now we can
plug other interesting functions <span class="arithmatex">\(\psi\)</span> in order to alter the geometry.
Values in <span class="arithmatex">\(\mathcal{X}=[0,1]\)</span> may be interpreted as <em>coin flip</em> probabilities:
the higher, the more likely an event is to happen. An important property of a
binary random variable is its entropy. If <span class="arithmatex">\(x_i \in [0, 1]\)</span> denotes the
probability associated with coin <span class="arithmatex">\(i\)</span>, the entropy&nbsp;is</p>
<div class="arithmatex">\[H(x_i) = -x_i \log x_i - (1 - x_i) \log (1 - x_i).\]</div>
<p>We may extend this additively to vectors as <span class="arithmatex">\(H(x) = \sum_i H(x_i)\)</span>.
On <span class="arithmatex">\(\mathcal{X}=[0, 1]\)</span>, entropy is continuously differentiable and strictly
<strong>concave</strong>, maximized at <span class="arithmatex">\(x=0.5\)</span> and minimized at <span class="arithmatex">\(x=0\)</span> and <span class="arithmatex">\(x=1\)</span>.<label for="sn-8" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-8" class="margin-toggle"/><span class="sidenote"><span class="arithmatex">\(H(0.5) =
\log 2,\)</span><br><span class="arithmatex">\(H(0)=H(1)=0\)</span>.</span>
Its gradient&nbsp;is </p>
<div class="arithmatex">\[ (-h)(x) \coloneqq \nabla(-H)(x) = \log(x) - \log(1-x), \]</div>
<p>an invertible function with&nbsp;inverse</p>
<div class="arithmatex">\[ (-h)^{-1}(u) = \sigma(u). \]</div>
<!--
The entropy induces a Bregman divergence $D_{-H}$, which after some manipulation
can be written as

$$D_{-H}(x, y) = x \log \frac{x}{y} - (1-x) \log \frac{1-x}{1-y}. $$
-->

<p>The mirror descent update induced by the negative entropy thus takes the (remarkable!)&nbsp;form</p>
<div class="arithmatex">\[ x^{(t+1)} = \sigma(\sigma^{-1}(x^{(t)}) - \alpha_t \nabla f(x^{(t)})). \]</div>
<p>Things are beginning to clear up! We can think of the pair of inverse functions
<span class="arithmatex">\((-h, \sigma)\)</span> as maps between <span class="arithmatex">\([0, 1]^d\)</span> and <span class="arithmatex">\(\reals^d\)</span>. We will call these
the <strong>primal</strong> and <strong>dual</strong> spaces, respectively. Mirror descent thus
first moves into dual (unconstrained) space, performs an update there, and then moves
back. Reparametrization rewrites the problem in dual coordinates and performs
gradient descent: this is not the same, and the trajectories are quite&nbsp;different!</p>
<p><img alt="quadratic landscape" src="/images/mirror_quad_lr0.010_md.png"></img></p>
<p>With a larger step size, we see that mirror descent takes much larger steps than
reparametrization&nbsp;does.</p>
<p><img alt="quadratic landscape" src="/images/mirror_quad_lr0.200_md.png"></img></p>
<p>Now that we figured out that we may think about the problem in primal or dual
coordinates, we may also visualize the optimization trajectory in dual&nbsp;coordinates.</p>
<p><img alt="quadratic landscape" src="/images/quad_lr0.010_md.png"></img></p>
    </div><!-- /.entry-content -->

  </article>
</section>
 </div>
<footer>
  <p>Powered by <a href="http://pelican.readthedocs.org">Pelican</a>.
  <a href="/privacy.html">Privacy policy</a>.</p>
</footer>
</div>
</body>
</html>